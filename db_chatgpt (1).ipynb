{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EfcE6qwrYYrv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content/drive/MyDrive/Colab Notebooks"
      ],
      "metadata": {
        "id": "pVXpGBBCY406"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/eosphoros-ai/DB-GPT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vM_N_wfYZ5A",
        "outputId": "99a5a51b-e5de-4749-b06f-f4d50b890b3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DB-GPT'...\n",
            "remote: Enumerating objects: 22967, done.\u001b[K\n",
            "remote: Counting objects: 100% (4639/4639), done.\u001b[K\n",
            "remote: Compressing objects: 100% (737/737), done.\u001b[K\n",
            "remote: Total 22967 (delta 3834), reused 4439 (delta 3776), pack-reused 18328\u001b[K\n",
            "Receiving objects: 100% (22967/22967), 172.82 MiB | 35.77 MiB/s, done.\n",
            "Resolving deltas: 100% (14882/14882), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# conda create -n dbgpt_env python=3.10\n",
        "# conda activate dbgpt_env\n",
        "%cd DB-GPT\n",
        "!pip install -e \".[default]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "56I4q4mvRSZm",
        "outputId": "8ab90a7d-7bb7-4f94-ec86-4ab46f01a3a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DB-GPT\n",
            "Obtaining file:///content/DB-GPT\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiohttp==3.8.4 (from db-gpt==0.4.2)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==5.1.0 (from db-gpt==0.4.2)\n",
            "  Downloading chardet-5.1.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources==5.12.0 (from db-gpt==0.4.2)\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting psutil==5.9.4 (from db-gpt==0.4.2)\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv==1.0.0 (from db-gpt==0.4.2)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting colorama==0.4.6 (from db-gpt==0.4.2)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (3.9.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (5.3.2)\n",
            "Collecting tokenizers==0.13.3 (from db-gpt==0.4.2)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.20.3 (from db-gpt==0.4.2)\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers (from db-gpt==0.4.2)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (3.20.3)\n",
            "Collecting zhipuai (from db-gpt==0.4.2)\n",
            "  Downloading zhipuai-1.0.7-py3-none-any.whl (7.9 kB)\n",
            "Collecting dashscope (from db-gpt==0.4.2)\n",
            "  Downloading dashscope-1.13.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython (from db-gpt==0.4.2)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fschat (from db-gpt==0.4.2)\n",
            "  Downloading fschat-0.2.33-py3-none-any.whl (217 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.3/217.3 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from db-gpt==0.4.2)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from db-gpt==0.4.2)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlparse==0.4.4 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.4.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.12.2)\n",
            "Collecting pandas==2.0.3 (from db-gpt==0.4.2)\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting auto-gpt-plugin-template (from db-gpt==0.4.2)\n",
            "  Downloading auto_gpt_plugin_template-0.0.3-py3-none-any.whl (3.4 kB)\n",
            "Collecting gTTS==2.3.1 (from db-gpt==0.4.2)\n",
            "  Downloading gTTS-2.3.1-py3-none-any.whl (28 kB)\n",
            "Collecting langchain>=0.0.286 (from db-gpt==0.4.2)\n",
            "  Downloading langchain-0.0.340-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting SQLAlchemy==2.0.22 (from db-gpt==0.4.2)\n",
            "  Downloading SQLAlchemy-2.0.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi==0.98.0 (from db-gpt==0.4.2)\n",
            "  Downloading fastapi-0.98.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymysql (from db-gpt==0.4.2)\n",
            "  Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting duckdb==0.8.1 (from db-gpt==0.4.2)\n",
            "  Downloading duckdb-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting duckdb-engine (from db-gpt==0.4.2)\n",
            "  Downloading duckdb_engine-0.9.2-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (4.19.2)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (4.35.2)\n",
            "Collecting alembic==1.12.0 (from db-gpt==0.4.2)\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl==3.1.2 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (3.1.2)\n",
            "Requirement already satisfied: xlrd==2.0.1 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (2.0.1)\n",
            "Collecting pympler (from db-gpt==0.4.2)\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy==3.5.3 (from db-gpt==0.4.2)\n",
            "  Downloading spacy-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb==0.4.10 (from db-gpt==0.4.2)\n",
            "  Downloading chromadb-0.4.10-py3-none-any.whl (422 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.4/422.4 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (3.5.1)\n",
            "Collecting bs4 (from db-gpt==0.4.2)\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-pptx (from db-gpt==0.4.2)\n",
            "  Downloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-docx (from db-gpt==0.4.2)\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf (from db-gpt==0.4.2)\n",
            "  Downloading pypdf-3.17.1-py3-none-any.whl (277 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.6/277.6 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart (from db-gpt==0.4.2)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.0.1 (from db-gpt==0.4.2)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2 (from db-gpt==0.4.2)\n",
            "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.0.2 (from db-gpt==0.4.2)\n",
            "  Downloading torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from db-gpt==0.4.2)\n",
            "  Downloading bitsandbytes-0.41.2.post2-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cpm_kernels (from db-gpt==0.4.2)\n",
            "  Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rocksdict (from db-gpt==0.4.2)\n",
            "  Downloading rocksdict-0.3.17-cp310-cp310-manylinux_2_28_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (1.0.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (1.3.1)\n",
            "Collecting Mako (from alembic==1.12.0->db-gpt==0.4.2)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic==1.12.0->db-gpt==0.4.2) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (2.31.0)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (1.10.13)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (4.66.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (1.23.5)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi==0.98.0->db-gpt==0.4.2)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS==2.3.1->db-gpt==0.4.2) (8.1.7)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl==3.1.2->db-gpt==0.4.2) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->db-gpt==0.4.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->db-gpt==0.4.2) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas==2.0.3->db-gpt==0.4.2)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (2.0.10)\n",
            "Collecting typer<0.8.0,>=0.3.0 (from spacy==3.5.3->db-gpt==0.4.2)\n",
            "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (6.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (3.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy==2.0.22->db-gpt==0.4.2) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->db-gpt==0.4.2) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->db-gpt==0.4.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->db-gpt==0.4.2) (3.2.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2->db-gpt==0.4.2) (9.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->db-gpt==0.4.2) (0.41.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->db-gpt==0.4.2) (3.27.7)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->db-gpt==0.4.2)\n",
            "  Downloading lit-17.0.5.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->db-gpt==0.4.2) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->db-gpt==0.4.2) (0.19.4)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.286->db-gpt==0.4.2) (3.7.1)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain>=0.0.286->db-gpt==0.4.2)\n",
            "  Downloading dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain>=0.0.286->db-gpt==0.4.2)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain>=0.0.286->db-gpt==0.4.2)\n",
            "  Downloading langsmith-0.0.66-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.286->db-gpt==0.4.2) (8.2.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->db-gpt==0.4.2) (2023.6.3)\n",
            "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting transformers>=4.31.0 (from db-gpt==0.4.2)\n",
            "  Downloading transformers-4.35.1-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->db-gpt==0.4.2) (0.4.0)\n",
            "Collecting abstract-singleton (from auto-gpt-plugin-template->db-gpt==0.4.2)\n",
            "  Downloading abstract_singleton-1.0.1-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->db-gpt==0.4.2) (4.11.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->db-gpt==0.4.2)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown2[all] (from fschat->db-gpt==0.4.2)\n",
            "  Downloading markdown2-2.4.10-py2.py3-none-any.whl (39 kB)\n",
            "Collecting nh3 (from fschat->db-gpt==0.4.2)\n",
            "  Downloading nh3-0.2.14-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat->db-gpt==0.4.2) (3.0.41)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat->db-gpt==0.4.2) (13.7.0)\n",
            "Collecting shortuuid (from fschat->db-gpt==0.4.2)\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting tiktoken (from fschat->db-gpt==0.4.2)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from GitPython->db-gpt==0.4.2)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->db-gpt==0.4.2) (2023.7.22)\n",
            "Collecting httpcore (from httpx->db-gpt==0.4.2)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->db-gpt==0.4.2) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->db-gpt==0.4.2) (1.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->db-gpt==0.4.2) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->db-gpt==0.4.2) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->db-gpt==0.4.2) (0.13.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->db-gpt==0.4.2) (0.2.10)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx->db-gpt==0.4.2) (4.9.3)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx->db-gpt==0.4.2)\n",
            "  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->db-gpt==0.4.2) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->db-gpt==0.4.2) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->db-gpt==0.4.2) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->db-gpt==0.4.2) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers->db-gpt==0.4.2)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyJWT in /usr/lib/python3/dist-packages (from zhipuai->db-gpt==0.4.2) (2.3.0)\n",
            "Collecting dataclasses (from zhipuai->db-gpt==0.4.2)\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.286->db-gpt==0.4.2) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.286->db-gpt==0.4.2)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.286->db-gpt==0.4.2)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython->db-gpt==0.4.2)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate>=0.20.3->db-gpt==0.4.2) (2023.6.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain>=0.0.286->db-gpt==0.4.2)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->db-gpt==0.4.2) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->db-gpt==0.4.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->db-gpt==0.4.2) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->db-gpt==0.4.2) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->db-gpt==0.4.2) (3.1.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.10->db-gpt==0.4.2) (23.5.26)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.10->db-gpt==0.4.2) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.10->db-gpt==0.4.2) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat->db-gpt==0.4.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat->db-gpt==0.4.2) (2.16.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.3->db-gpt==0.4.2) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.3->db-gpt==0.4.2) (0.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==0.4.10->db-gpt==0.4.2)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->db-gpt==0.4.2) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.5.3->db-gpt==0.4.2) (2.1.3)\n",
            "Collecting wavedrom (from markdown2[all]->fschat->db-gpt==0.4.2)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->db-gpt==0.4.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->db-gpt==0.4.2) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->db-gpt==0.4.2) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat->db-gpt==0.4.2) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.286->db-gpt==0.4.2)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->fschat->db-gpt==0.4.2)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: bs4, sentence-transformers, pypika, lit, wavedrom\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=b5010faddbe1cf4b21eeb71650488b672a6912d2ec237b4be4391ec1e2e85fe1\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=8afdc2150e8bb8ccbeeaf6ea1386b06ccfd8281c2d3f2ba1fecd7de227de1540\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=cbd2752978ec9d13c3f570a30a3a250b7fb53513a1bae5e99d12f851beea215b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.5-py3-none-any.whl size=93256 sha256=15fe7788e87cc5b57a32dd5e99a3112bc5b2856b13c9a9dceab08f5624532ad0\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/87/8e/5a42c0d4be23362b68bbff33b17f3c35a3df44f1cd2f5a24b4\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30053 sha256=9306e1d27308d638fb5e10887114cced7189a03da9f880aca49338832dd7a403\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
            "Successfully built bs4 sentence-transformers pypika lit wavedrom\n",
            "Installing collected packages: tokenizers, sentencepiece, rocksdict, pypika, nh3, monotonic, lit, duckdb, dataclasses, cpm_kernels, bitsandbytes, XlsxWriter, websockets, uvloop, tzdata, typer, svgwrite, SQLAlchemy, smmap, shortuuid, python-multipart, python-dotenv, python-docx, pypdf, pymysql, pympler, pulsar-client, psutil, overrides, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, mypy-extensions, marshmallow, markdown2, Mako, jsonpointer, importlib-resources, humanfriendly, httptools, h11, colorama, chroma-hnswlib, chardet, bcrypt, backoff, abstract-singleton, zhipuai, wavedrom, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, python-pptx, posthog, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, langsmith, jsonpatch, httpcore, gTTS, gitdb, duckdb-engine, coloredlogs, bs4, auto-gpt-plugin-template, alembic, aiohttp, transformers, onnxruntime, httpx, GitPython, fastapi, db-gpt, dataclasses-json, dashscope, spacy, langchain, fschat, chromadb, triton, torch, torchvision, torchaudio, sentence-transformers, accelerate\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: duckdb\n",
            "    Found existing installation: duckdb 0.9.2\n",
            "    Uninstalling duckdb-0.9.2:\n",
            "      Successfully uninstalled duckdb-0.9.2\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.0\n",
            "    Uninstalling typer-0.9.0:\n",
            "      Successfully uninstalled typer-0.9.0\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.23\n",
            "    Uninstalling SQLAlchemy-2.0.23:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.23\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 6.1.1\n",
            "    Uninstalling importlib-resources-6.1.1:\n",
            "      Successfully uninstalled importlib-resources-6.1.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.8.6\n",
            "    Uninstalling aiohttp-3.8.6:\n",
            "      Successfully uninstalled aiohttp-3.8.6\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Running setup.py develop for db-gpt\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu118\n",
            "    Uninstalling torchvision-0.16.0+cu118:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu118\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.1.0+cu118\n",
            "    Uninstalling torchaudio-2.1.0+cu118:\n",
            "      Successfully uninstalled torchaudio-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.0.3 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.40 Mako-1.3.0 SQLAlchemy-2.0.22 XlsxWriter-3.1.9 abstract-singleton-1.0.1 accelerate-0.24.1 aiohttp-3.8.4 alembic-1.12.0 auto-gpt-plugin-template-0.0.3 backoff-2.2.1 bcrypt-4.0.1 bitsandbytes-0.41.2.post2 bs4-0.0.1 chardet-5.1.0 chroma-hnswlib-0.7.3 chromadb-0.4.10 colorama-0.4.6 coloredlogs-15.0.1 cpm_kernels-1.0.11 dashscope-1.13.3 dataclasses-0.6 dataclasses-json-0.6.2 db-gpt-0.4.2 duckdb-0.8.1 duckdb-engine-0.9.2 fastapi-0.98.0 fschat-0.2.33 gTTS-2.3.1 gitdb-4.0.11 h11-0.14.0 httpcore-1.0.2 httptools-0.6.1 httpx-0.25.1 humanfriendly-10.0 importlib-resources-5.12.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.340 langsmith-0.0.66 lit-17.0.5 markdown2-2.4.10 marshmallow-3.20.1 monotonic-1.6 mypy-extensions-1.0.0 nh3-0.2.14 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 onnxruntime-1.16.3 overrides-7.4.0 pandas-2.0.3 posthog-3.0.2 psutil-5.9.4 pulsar-client-3.3.0 pympler-1.0.1 pymysql-1.1.0 pypdf-3.17.1 pypika-0.48.9 python-docx-1.1.0 python-dotenv-1.0.0 python-multipart-0.0.6 python-pptx-0.6.23 rocksdict-0.3.17 sentence-transformers-2.2.2 sentencepiece-0.1.99 shortuuid-1.0.11 smmap-5.0.1 spacy-3.5.3 starlette-0.27.0 svgwrite-1.4.3 tiktoken-0.5.1 tokenizers-0.13.3 torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2 transformers-4.33.3 triton-2.0.0 typer-0.7.0 typing-inspect-0.9.0 tzdata-2023.3 uvicorn-0.24.0.post1 uvloop-0.19.0 watchfiles-0.21.0 wavedrom-2.0.3.post3 websockets-12.0 zhipuai-1.0.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp .env.template .env"
      ],
      "metadata": {
        "id": "defy4B9WRUn-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git-lfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aanIselpRW0y",
        "outputId": "515db560-b10d-40b3-a178-c329e542a967"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e \".[openai]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJwZW4OjTJsJ",
        "outputId": "e74ef48d-9fa6-4e43-8361-7db7799e94dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/DB-GPT\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp==3.8.4 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (3.8.4)\n",
            "Requirement already satisfied: chardet==5.1.0 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (5.1.0)\n",
            "Requirement already satisfied: importlib-resources==5.12.0 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (5.12.0)\n",
            "Requirement already satisfied: psutil==5.9.4 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (5.9.4)\n",
            "Requirement already satisfied: python-dotenv==1.0.0 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (1.0.0)\n",
            "Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.4.6)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (3.9.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (5.3.2)\n",
            "Collecting openai (from db-gpt==0.4.2)\n",
            "  Downloading openai-1.3.5-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.5.1)\n",
            "Requirement already satisfied: fschat in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.2.33)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (15.0.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.25.1)\n",
            "Requirement already satisfied: sqlparse==0.4.4 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.4.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.12.2)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (2.0.3)\n",
            "Requirement already satisfied: auto-gpt-plugin-template in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.0.3)\n",
            "Requirement already satisfied: gTTS==2.3.1 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (2.3.1)\n",
            "Requirement already satisfied: langchain>=0.0.286 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.0.340)\n",
            "Requirement already satisfied: SQLAlchemy==2.0.22 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (2.0.22)\n",
            "Requirement already satisfied: fastapi==0.98.0 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.98.0)\n",
            "Requirement already satisfied: pymysql in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (1.1.0)\n",
            "Requirement already satisfied: duckdb==0.8.1 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.8.1)\n",
            "Requirement already satisfied: duckdb-engine in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.9.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (4.19.2)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (4.33.3)\n",
            "Requirement already satisfied: alembic==1.12.0 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (1.12.0)\n",
            "Requirement already satisfied: openpyxl==3.1.2 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (3.1.2)\n",
            "Requirement already satisfied: xlrd==2.0.1 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (2.0.1)\n",
            "Requirement already satisfied: pympler in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (1.0.1)\n",
            "Requirement already satisfied: spacy==3.5.3 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (3.5.3)\n",
            "Requirement already satisfied: chromadb==0.4.10 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.4.10)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (3.5.1)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.0.1)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.6.23)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (1.1.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (3.17.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from db-gpt==0.4.2) (0.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp==3.8.4->db-gpt==0.4.2) (1.3.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic==1.12.0->db-gpt==0.4.2) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic==1.12.0->db-gpt==0.4.2) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (2.31.0)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (1.10.13)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (0.7.3)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (0.24.0.post1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (3.0.2)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (3.3.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (1.16.3)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (0.13.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (4.66.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (7.4.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.10->db-gpt==0.4.2) (1.23.5)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.98.0->db-gpt==0.4.2) (0.27.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS==2.3.1->db-gpt==0.4.2) (8.1.7)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl==3.1.2->db-gpt==0.4.2) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->db-gpt==0.4.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->db-gpt==0.4.2) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->db-gpt==0.4.2) (2023.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (2.0.10)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (6.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->db-gpt==0.4.2) (3.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy==2.0.22->db-gpt==0.4.2) (3.0.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.286->db-gpt==0.4.2) (6.0.1)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.286->db-gpt==0.4.2) (3.7.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.286->db-gpt==0.4.2) (0.6.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.286->db-gpt==0.4.2) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.286->db-gpt==0.4.2) (0.0.66)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.286->db-gpt==0.4.2) (8.2.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->db-gpt==0.4.2) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->db-gpt==0.4.2) (0.19.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->db-gpt==0.4.2) (2023.6.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->db-gpt==0.4.2) (0.4.0)\n",
            "Requirement already satisfied: abstract-singleton in /usr/local/lib/python3.10/dist-packages (from auto-gpt-plugin-template->db-gpt==0.4.2) (1.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->db-gpt==0.4.2) (4.11.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->db-gpt==0.4.2) (10.0)\n",
            "Requirement already satisfied: markdown2[all] in /usr/local/lib/python3.10/dist-packages (from fschat->db-gpt==0.4.2) (2.4.10)\n",
            "Requirement already satisfied: nh3 in /usr/local/lib/python3.10/dist-packages (from fschat->db-gpt==0.4.2) (0.2.14)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat->db-gpt==0.4.2) (3.0.41)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat->db-gpt==0.4.2) (13.7.0)\n",
            "Requirement already satisfied: shortuuid in /usr/local/lib/python3.10/dist-packages (from fschat->db-gpt==0.4.2) (1.0.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->db-gpt==0.4.2) (2023.7.22)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx->db-gpt==0.4.2) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->db-gpt==0.4.2) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->db-gpt==0.4.2) (1.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->db-gpt==0.4.2) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->db-gpt==0.4.2) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->db-gpt==0.4.2) (0.13.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->db-gpt==0.4.2) (1.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->db-gpt==0.4.2) (0.2.10)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx->db-gpt==0.4.2) (4.9.3)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx->db-gpt==0.4.2) (9.4.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx->db-gpt==0.4.2) (3.1.9)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn->db-gpt==0.4.2) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain>=0.0.286->db-gpt==0.4.2) (1.1.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.286->db-gpt==0.4.2) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.286->db-gpt==0.4.2) (0.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers>=4.31.0->db-gpt==0.4.2) (2023.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.286->db-gpt==0.4.2) (2.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->db-gpt==0.4.2) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->db-gpt==0.4.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->db-gpt==0.4.2) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->db-gpt==0.4.2) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->db-gpt==0.4.2) (3.1.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.10->db-gpt==0.4.2) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.10->db-gpt==0.4.2) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.10->db-gpt==0.4.2) (1.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.10->db-gpt==0.4.2) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.10->db-gpt==0.4.2) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.10->db-gpt==0.4.2) (2.2.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.10->db-gpt==0.4.2) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat->db-gpt==0.4.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat->db-gpt==0.4.2) (2.16.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.3->db-gpt==0.4.2) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.3->db-gpt==0.4.2) (0.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.10->db-gpt==0.4.2) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.10->db-gpt==0.4.2) (0.6.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.10->db-gpt==0.4.2) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.10->db-gpt==0.4.2) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.10->db-gpt==0.4.2) (12.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->db-gpt==0.4.2) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.5.3->db-gpt==0.4.2) (2.1.3)\n",
            "Requirement already satisfied: wavedrom in /usr/local/lib/python3.10/dist-packages (from markdown2[all]->fschat->db-gpt==0.4.2) (2.0.3.post3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat->db-gpt==0.4.2) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.286->db-gpt==0.4.2) (1.0.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.10->db-gpt==0.4.2) (1.3.0)\n",
            "Requirement already satisfied: svgwrite in /usr/local/lib/python3.10/dist-packages (from wavedrom->markdown2[all]->fschat->db-gpt==0.4.2) (1.4.3)\n",
            "Installing collected packages: openai, db-gpt\n",
            "  Attempting uninstall: db-gpt\n",
            "    Found existing installation: db-gpt 0.4.2\n",
            "    Uninstalling db-gpt-0.4.2:\n",
            "      Successfully uninstalled db-gpt-0.4.2\n",
            "  Running setup.py develop for db-gpt\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed db-gpt-0.4.2 openai-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models"
      ],
      "metadata": {
        "id": "_iRx4uXCTPIv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd models\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXSJLpFQTV7R",
        "outputId": "b04568f7-6a31-41c8-8f57-ee68c5d04235"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DB-GPT/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/moka-ai/m3e-large\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K10--oJ9TXJG",
        "outputId": "c0efb248-41a1-43d8-bb9c-cc38f27fa6ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'm3e-large'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 12\u001b[K\n",
            "Unpacking objects: 100% (12/12), 167.45 KiB | 4.92 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/GanymedeNil/text2vec-large-chinese\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8tRrrYkTZcb",
        "outputId": "015f2c90-45ff-442e-acdc-8ef19cebc645"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'text2vec-large-chinese'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "Unpacking objects:   3% (1/27)\rUnpacking objects:   7% (2/27)\rUnpacking objects:  11% (3/27)\rUnpacking objects:  14% (4/27)\rUnpacking objects:  18% (5/27)\rUnpacking objects:  22% (6/27)\rUnpacking objects:  25% (7/27)\rUnpacking objects:  29% (8/27)\rUnpacking objects:  33% (9/27)\rUnpacking objects:  37% (10/27)\rUnpacking objects:  40% (11/27)\rUnpacking objects:  44% (12/27)\rUnpacking objects:  48% (13/27)\rUnpacking objects:  51% (14/27)\rUnpacking objects:  55% (15/27)\rremote: Total 27 (delta 0), reused 0 (delta 0), pack-reused 24\u001b[K\n",
            "Unpacking objects: 100% (27/27), 161.09 KiB | 5.75 MiB/s, done.\n",
            "Filtering content: 100% (2/2), 2.42 GiB | 47.89 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaG3bVI4TbLQ",
        "outputId": "9157dd4b-88b5-4275-efdb-15bb2d988b70"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DB-GPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('.env', 'r') as file:\n",
        "    print(file.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kReQ01VTcgC",
        "outputId": "00a6f2aa-e0f7-42d1-8b8b-0eb59703ac5d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#*******************************************************************#\n",
            "#**             DB-GPT  - GENERAL SETTINGS                        **#  \n",
            "#*******************************************************************#\n",
            "## DISABLED_COMMAND_CATEGORIES - The list of categories of commands that are disabled. Each of the below are an option:\n",
            "## pilot.commands.query_execute\n",
            "\n",
            "## For example, to disable coding related features, uncomment the next line\n",
            "# DISABLED_COMMAND_CATEGORIES=   \n",
            "\n",
            "#*******************************************************************#\n",
            "#**                        Webserver Port                         **#\n",
            "#*******************************************************************#\n",
            "WEB_SERVER_PORT=7860\n",
            "\n",
            "#*******************************************************************#\n",
            "#***                       LLM PROVIDER                          ***#\n",
            "#*******************************************************************#\n",
            "\n",
            "# TEMPERATURE=0\n",
            "\n",
            "#*******************************************************************#\n",
            "#**                         LLM MODELS                            **#\n",
            "#*******************************************************************#\n",
            "# LLM_MODEL, see /pilot/configs/model_config.LLM_MODEL_CONFIG\n",
            "LLM_MODEL=vicuna-13b-v1.5\n",
            "## LLM model path, by default, DB-GPT will read the model path from LLM_MODEL_CONFIG based on the LLM_MODEL.\n",
            "## Of course you can specify your model path according to LLM_MODEL_PATH\n",
            "## In DB-GPT, the priority from high to low to read model path:\n",
            "##    1. environment variable with key: {LLM_MODEL}_MODEL_PATH (Avoid multi-model conflicts)\n",
            "##    2. environment variable with key: MODEL_PATH\n",
            "##    3. environment variable with key: LLM_MODEL_PATH\n",
            "##    4. the config in /pilot/configs/model_config.LLM_MODEL_CONFIG\n",
            "# LLM_MODEL_PATH=/app/models/vicuna-13b-v1.5\n",
            "# LLM_PROMPT_TEMPLATE=vicuna_v1.1\n",
            "MODEL_SERVER=http://127.0.0.1:8000\n",
            "LIMIT_MODEL_CONCURRENCY=5\n",
            "MAX_POSITION_EMBEDDINGS=4096\n",
            "QUANTIZE_QLORA=True\n",
            "QUANTIZE_8bit=True\n",
            "# QUANTIZE_4bit=False\n",
            "## SMART_LLM_MODEL - Smart language model (Default: vicuna-13b)\n",
            "## FAST_LLM_MODEL - Fast language model (Default: chatglm-6b)\n",
            "# SMART_LLM_MODEL=vicuna-13b\n",
            "# FAST_LLM_MODEL=chatglm-6b\n",
            "## Proxy llm backend, this configuration is only valid when \"LLM_MODEL=proxyllm\", When we use the rest API provided by deployment frameworks like fastchat as a proxyllm, \n",
            "## \"PROXYLLM_BACKEND\" is the model they actually deploy. We can use \"PROXYLLM_BACKEND\" to load the prompt of the corresponding scene. \n",
            "# PROXYLLM_BACKEND=\n",
            "\n",
            "### You can configure parameters for a specific model with {model name}_{config key}=xxx\n",
            "### See /pilot/model/parameter.py\n",
            "## prompt template for current model\n",
            "# llama_cpp_prompt_template=vicuna_v1.1\n",
            "## llama-2-70b must be 8\n",
            "# llama_cpp_n_gqa=8\n",
            "## Model path\n",
            "# llama_cpp_model_path=/data/models/TheBloke/vicuna-13B-v1.5-GGUF/vicuna-13b-v1.5.Q4_K_M.gguf\n",
            "\n",
            "### LLM cache\n",
            "## Enable Model cache\n",
            "# MODEL_CACHE_ENABLE=True\n",
            "## The storage type of model cache, now supports: memory, disk\n",
            "# MODEL_CACHE_STORAGE_TYPE=disk\n",
            "## The max cache data in memory, we always store cache data in memory fist for high speed. \n",
            "# MODEL_CACHE_MAX_MEMORY_MB=256\n",
            "## The dir to save cache data, this configuration is only valid when MODEL_CACHE_STORAGE_TYPE=disk\n",
            "## The default dir is pilot/data/model_cache\n",
            "# MODEL_CACHE_STORAGE_DISK_DIR=\n",
            "\n",
            "#*******************************************************************#\n",
            "#**                         EMBEDDING SETTINGS                    **#\n",
            "#*******************************************************************#\n",
            "EMBEDDING_MODEL=text2vec\n",
            "#EMBEDDING_MODEL=m3e-large\n",
            "#EMBEDDING_MODEL=bge-large-en\n",
            "#EMBEDDING_MODEL=bge-large-zh\n",
            "KNOWLEDGE_CHUNK_SIZE=500\n",
            "KNOWLEDGE_SEARCH_TOP_SIZE=5\n",
            "#KNOWLEDGE_CHUNK_OVERLAP=50\n",
            "# Control whether to display the source document of knowledge on the front end.\n",
            "KNOWLEDGE_CHAT_SHOW_RELATIONS=False\n",
            "## EMBEDDING_TOKENIZER   - Tokenizer to use for chunking large inputs\n",
            "## EMBEDDING_TOKEN_LIMIT - Chunk size limit for large inputs\n",
            "# EMBEDDING_MODEL=all-MiniLM-L6-v2\n",
            "# EMBEDDING_TOKENIZER=all-MiniLM-L6-v2\n",
            "# EMBEDDING_TOKEN_LIMIT=8191\n",
            "\n",
            "## Openai embedding model, See /pilot/model/parameter.py\n",
            "# EMBEDDING_MODEL=proxy_openai\n",
            "# proxy_openai_proxy_server_url=https://api.openai.com/v1\n",
            "# proxy_openai_proxy_api_key={your-openai-sk}\n",
            "# proxy_openai_proxy_backend=text-embedding-ada-002\n",
            "\n",
            "\n",
            "#*******************************************************************#\n",
            "#**                  DATABASE SETTINGS                            **#\n",
            "#*******************************************************************#\n",
            "### SQLite database (Current default database)\n",
            "LOCAL_DB_PATH=data/default_sqlite.db\n",
            "LOCAL_DB_TYPE=sqlite\n",
            "\n",
            "### MYSQL database\n",
            "# LOCAL_DB_TYPE=mysql\n",
            "# LOCAL_DB_USER=root\n",
            "# LOCAL_DB_PASSWORD=aa12345678\n",
            "# LOCAL_DB_HOST=127.0.0.1\n",
            "# LOCAL_DB_PORT=3306\n",
            "# LOCAL_DB_NAME=dbgpt\n",
            "### This option determines the storage location of conversation records. The default is not configured to the old version of duckdb. It can be optionally db or file (if the value is db, the database configured by LOCAL_DB will be used)\n",
            "#CHAT_HISTORY_STORE_TYPE=db\n",
            "\n",
            "#*******************************************************************#\n",
            "#**                         COMMANDS                              **#\n",
            "#*******************************************************************#\n",
            "EXECUTE_LOCAL_COMMANDS=False\n",
            "\n",
            "\n",
            "\n",
            "#*******************************************************************#\n",
            "#**                  ALLOWLISTED PLUGINS                          **#\n",
            "#*******************************************************************#\n",
            "\n",
            "#ALLOWLISTED_PLUGINS - Sets the listed plugins that are allowed (Example: plugin1,plugin2,plugin3)\n",
            "#DENYLISTED_PLUGINS - Sets the listed plugins that are not allowed (Example: plugin1,plugin2,plugin3)\n",
            "ALLOWLISTED_PLUGINS=\n",
            "DENYLISTED_PLUGINS=\n",
            "\n",
            "\n",
            "#*******************************************************************#\n",
            "#**                 CHAT PLUGIN SETTINGS                          **#\n",
            "#*******************************************************************#\n",
            "# CHAT_MESSAGES_ENABLED - Enable chat messages (Default: False)\n",
            "# CHAT_MESSAGES_ENABLED=False\n",
            "\n",
            "\n",
            "#*******************************************************************#\n",
            "#**                  VECTOR STORE SETTINGS                       **#\n",
            "#*******************************************************************#\n",
            "### Chroma vector db config\n",
            "VECTOR_STORE_TYPE=Chroma\n",
            "#CHROMA_PERSIST_PATH=/root/DB-GPT/pilot/data\n",
            "\n",
            "### Milvus vector db config\n",
            "#VECTOR_STORE_TYPE=Milvus\n",
            "#MILVUS_URL=127.0.0.1\n",
            "#MILVUS_PORT=19530\n",
            "#MILVUS_USERNAME\n",
            "#MILVUS_PASSWORD\n",
            "#MILVUS_SECURE=\n",
            "\n",
            "### Weaviate vector db config\n",
            "#VECTOR_STORE_TYPE=Weaviate\n",
            "#WEAVIATE_URL=https://kt-region-m8hcy0wc.weaviate.network\n",
            "\n",
            "#*******************************************************************#\n",
            "#**                  WebServer Language Support                   **#\n",
            "#*******************************************************************#\n",
            "LANGUAGE=en\n",
            "#LANGUAGE=zh\n",
            "\n",
            "\n",
            "#*******************************************************************#\n",
            "# **    PROXY_SERVER (openai interface | chatGPT proxy service), use chatGPT as your LLM.\n",
            "# ** if your server can visit openai, please set PROXY_SERVER_URL=https://api.openai.com/v1/chat/completions\n",
            "# ** else if you have a chatgpt proxy server, you can set PROXY_SERVER_URL={your-proxy-serverip:port/xxx}\n",
            "#*******************************************************************#\n",
            "LLM_MODEL=chatgpt_proxyllm\n",
            "PROXY_API_KEY={api_key}\n",
            "PROXY_SERVER_URL=https://api.openai.com/v1/chat/completions\n",
            "\n",
            "# from https://bard.google.com/     f12-> application-> __Secure-1PSID\n",
            "BARD_PROXY_API_KEY={your-bard-token}\n",
            "\n",
            "#*******************************************************************#\n",
            "# **  PROXY_SERVER +                                              **#\n",
            "#*******************************************************************#\n",
            "\n",
            "# Aliyun tongyi\n",
            "TONGYI_PROXY_API_KEY={your-tongyi-sk}\n",
            "\n",
            "## Baidu wenxin\n",
            "#WEN_XIN_MODEL_VERSION={version}\n",
            "#WEN_XIN_API_KEY={your-wenxin-sk}\n",
            "#WEN_XIN_SECRET_KEY={your-wenxin-sct}\n",
            "\n",
            "## Zhipu\n",
            "#ZHIPU_MODEL_VERSION={version}\n",
            "#ZHIPU_PROXY_API_KEY={your-zhipu-sk}\n",
            "\n",
            "## Baichuan\n",
            "#BAICHUN_MODEL_NAME={version}\n",
            "#BAICHUAN_PROXY_API_KEY={your-baichuan-sk}\n",
            "#BAICHUAN_PROXY_API_SECRET={your-baichuan-sct}\n",
            "\n",
            "\n",
            "#*******************************************************************#\n",
            "#**    SUMMARY_CONFIG                                             **#\n",
            "#*******************************************************************#\n",
            "SUMMARY_CONFIG=FAST\n",
            "\n",
            "#*******************************************************************#\n",
            "#**    MUlti-GPU                                                  **#\n",
            "#*******************************************************************#\n",
            "## See https://developer.nvidia.com/blog/cuda-pro-tip-control-gpu-visibility-cuda_visible_devices/\n",
            "## If CUDA_VISIBLE_DEVICES is not configured, all available gpus will be used\n",
            "# CUDA_VISIBLE_DEVICES=0\n",
            "## You can configure the maximum memory used by each GPU.\n",
            "# MAX_GPU_MEMORY=16Gib\n",
            "\n",
            "#*******************************************************************#\n",
            "#**                         LOG                                   **#\n",
            "#*******************************************************************#\n",
            "# FATAL, ERROR, WARNING, WARNING, INFO, DEBUG, NOTSET\n",
            "DBGPT_LOG_LEVEL=INFO\n",
            "# LOG dir, default: ./logs\n",
            "#DBGPT_LOG_DIR=\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash ./scripts/examples/load_examples.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlszVP8nVmaC",
        "outputId": "3a1e8454-1fec-4d22-bd63-7600c2403184"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sqlite3 not found, please install sqlite3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "b5eFHZ2kdt9l",
        "outputId": "21344f90-10fb-4e72-d9da-818a4312ae91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DB-GPT'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd DB-GPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m-0T7HGe-fJ",
        "outputId": "6e99e971-e5e0-4c3b-cfa7-8566618c83f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'DB-GPT'\n",
            "/content/DB-GPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pilot/server/dbgpt_server.py"
      ],
      "metadata": {
        "id": "P0vtMsw8Vp23",
        "outputId": "60211ed1-cc76-49d7-dcd0-a4331a22dae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=========================== WebWerverParameters ===========================\n",
            "\n",
            "host: 0.0.0.0\n",
            "port: 5000\n",
            "daemon: False\n",
            "controller_addr: None\n",
            "model_name: None\n",
            "share: False\n",
            "remote_embedding: False\n",
            "log_level: INFO\n",
            "light: False\n",
            "log_file: dbgpt_webserver.log\n",
            "tracer_file: dbgpt_webserver_tracer.jsonl\n",
            "tracer_storage_cls: None\n",
            "disable_alembic_upgrade: False\n",
            "\n",
            "======================================================================\n",
            "\n",
            "\n",
            "5079fd79cc41 (head)\n",
            "heads:None\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "Generating /content/DB-GPT/pilot/meta_data/alembic/versions/f82afc12106b_dbgpt_ddl_upate.py ...  done\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "INFO  [alembic.runtime.migration] Running upgrade 5079fd79cc41 -> f82afc12106b, dbgpt ddl upate\n",
            "INFO  [pilot.model.cluster.worker.embedding_worker] [EmbeddingsModelWorker] Parameters of device is None, use cuda\n",
            "WARNI [sentence_transformers.SentenceTransformer] No sentence-transformers model found with name /content/DB-GPT/models/text2vec-large-chinese. Creating a new one with MEAN pooling.\n",
            "2023-11-23 19:18:06.037839: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-23 19:18:06.037904: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-23 19:18:06.037944: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-23 19:18:07.417851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO  [pilot.awel.dag.loader] Importing /content/DB-GPT/examples/awel/simple_dag_example.py\n",
            "INFO  [pilot.awel.dag.loader] Found dag <pilot.awel.dag.base.DAG object at 0x79b1362b6320> from mod <module 'unusual_prefix_12ba5feb4b209a3ecbc1ba41f5ada12913aec4e2_simple_dag_example' from '/content/DB-GPT/examples/awel/simple_dag_example.py'> and model file /content/DB-GPT/examples/awel/simple_dag_example.py\n",
            "INFO  [pilot.awel.dag.loader] Importing /content/DB-GPT/examples/awel/simple_rag_example.py\n",
            "INFO  [pilot.awel.dag.loader] Found dag <pilot.awel.dag.base.DAG object at 0x79b1362b6c20> from mod <module 'unusual_prefix_7d5498f3c780f1a3053523d3278d684b686f71a3_simple_rag_example' from '/content/DB-GPT/examples/awel/simple_rag_example.py'> and model file /content/DB-GPT/examples/awel/simple_rag_example.py\n",
            "INFO  [pilot.awel.dag.loader] Importing /content/DB-GPT/examples/awel/simple_chat_dag_example.py\n",
            "INFO  [pilot.awel.dag.loader] Found dag <pilot.awel.dag.base.DAG object at 0x79b1362b7880> from mod <module 'unusual_prefix_6e78c8e09d739f61de4128fb3966eb9277defe3f_simple_chat_dag_example' from '/content/DB-GPT/examples/awel/simple_chat_dag_example.py'> and model file /content/DB-GPT/examples/awel/simple_chat_dag_example.py\n",
            "INFO  [pilot.awel.trigger.trigger_manager] Register trigger <pilot.awel.trigger.http_trigger.HttpTrigger object at 0x79b1362b62c0>\n",
            "INFO  [pilot.awel.trigger.trigger_manager] Register trigger <pilot.awel.trigger.http_trigger.HttpTrigger object at 0x79b1362b6560>\n",
            "INFO  [pilot.awel.trigger.trigger_manager] Register trigger <pilot.awel.trigger.http_trigger.HttpTrigger object at 0x79b1362b77c0>\n",
            "INFO  [pilot.awel.trigger.trigger_manager] Include router <fastapi.routing.APIRouter object at 0x79b1362b52d0> to prefix path /api/v1/awel/trigger\n",
            "Model Unified Deployment Mode!\n",
            "INFO  [pilot.model.adapter] Found llm model adapter with model name: chatgpt_proxyllm, <pilot.model.adapter.ProxyllmAdapter object at 0x79b19fb815a0>\n",
            "Get model chat adapter with model name chatgpt_proxyllm, <pilot.server.chat_adapter.ProxyllmChatAdapter object at 0x79b19fb82140>\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m6431\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "INFO  [pilot.model.cluster.worker.manager] Begin start all worker, apply_req: None\n",
            "INFO  [pilot.model.cluster.worker.manager] Apply req: None, apply_func: <function LocalWorkerManager._start_all_worker.<locals>._start_worker at 0x79b130e7b250>\n",
            "INFO  [pilot.model.cluster.worker.manager] Apply to all workers\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:5000\u001b[0m (Press CTRL+C to quit)\n",
            "INFO  [pilot.model.cluster.worker.default_worker] Begin load model, model params: \n",
            "\n",
            "=========================== ProxyModelParameters ===========================\n",
            "\n",
            "model_name: chatgpt_proxyllm\n",
            "model_path: chatgpt_proxyllm\n",
            "proxy_server_url: https://api.openai.com/v1/chat/completions\n",
            "proxy_api_key: {******}\n",
            "proxy_api_base: None\n",
            "proxy_api_app_id: None\n",
            "proxy_api_type: None\n",
            "proxy_api_version: None\n",
            "http_proxy: None\n",
            "proxyllm_backend: None\n",
            "model_type: proxy\n",
            "device: cuda\n",
            "prompt_template: None\n",
            "max_context_size: 4096\n",
            "\n",
            "======================================================================\n",
            "\n",
            "\n",
            "INFO  [pilot.model.loader] Load proxyllm\n",
            "\u001b[32mINFO\u001b[0m:     127.0.0.1:56954 - \"\u001b[1mPOST /api/controller/models HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     127.0.0.1:56970 - \"\u001b[1mPOST /api/controller/models HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "begin run _add_app_startup_event\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /css/c921bbabe4b71b75.css HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/webpack-0be5f9261371f232.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/framework-b88f940c668b92b5.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/64-91b49d45b9846775.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/pages/_app-1c6d57125654d6ab.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/479-b20198841f9a6a1e.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/270-2f094a936d056513.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/553-df5701294eedae07.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/9-bb2c54d5c06ba4bf.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/main-bac3cf9c596e50fb.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /dXon0w257TT7JmleeTcnX/_ssgManifest.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/924-ba8e16df4d61ff5c.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/29107295-90b90cb30c825230.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /dXon0w257TT7JmleeTcnX/_buildManifest.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/981-ff77d5cc3ab95298.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/412-b911d4a677c64b70.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/411-d9eba2657c72f766.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/pages/index-d1740e3bc6dba7f5.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /LOGO.png HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /LOGO_1.png HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "/prompt/list params:  chat_scene=None sub_chat_scene=None prompt_type='common' content=None user_name=None prompt_name=None\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mPOST /prompt/list HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /api/v1/chat/dialogue/list HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mPOST /api/v1/chat/dialogue/scenes HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/947-5980a3ff49069ddd.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "INFO  [pilot.openapi.api_v1.api_v1] /controller/model/types\n",
            "INFO  [pilot.model.cluster.controller.controller] Get all instances with None, healthy_only: True\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /api/v1/model/types HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/837-e6d4d1eb9e057050.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/607-b224c640f6907e4b.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/pages/prompt-7f839dfd56bc4c20.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/813-cce9482e33f2430c.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/442-197e6cbc1e54109a.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/643-d8f53f40dd3c5b40.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/928-74244889bd7f2699.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/pages/database-3140f507fe61ccb8.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/75fc9c18-a784766a129ec5fb.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/pages/knowledge-8ada4ce8fa909bf5.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/551-266086fbfa0925ec.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/pages/models-80218c46bc1d8cfa.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/pages/agent-92e9dce47267e88d.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /models/chatgpt.png HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mPOST /api/v1/chat/dialogue/new HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/pages/chat-84fbba4764166684.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/355a6ca7.e6035af22360251e.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/960de000.b0c6e84211bcbef5.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /css/2df6b89b6fe4db33.css HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/0.3a0efeb4ac52ec8f.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /css/4047a8310a399ceb.css HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/739.82283c4d1eea95ee.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/955.228fa9fef23b31a4.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /chunks/396.2cca7f693431f729.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "chat_completions:chat_normal,,chatgpt_proxyllm\n",
            "/prompt/list params:  chat_scene=None sub_chat_scene=None prompt_type='common' content=None user_name=None prompt_name=None\n",
            "INFO  [pilot.openapi.api_v1.api_v1] get_chat_instance:conv_uid='315fd9ea-8a35-11ee-8834-0242ac1c000c' user_input='안녕' user_name='' chat_mode='chat_normal' select_param='' model_name='chatgpt_proxyllm' incremental=False\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mPOST /prompt/list HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "Get prompt template of scene_name: chat_normal with model_name: chatgpt_proxyllm, proxyllm_backend: None, language: en\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mPOST /api/v1/chat/mode/params/list?chat_mode=chat_normal HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /empty.png HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /api/v1/feedback/select HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "/content/DB-GPT/pilot/scene/base_chat.py:370: UserWarning: This method is deprecated - please use `generate_llm_messages`.\n",
            "  warnings.warn(\"This method is deprecated - please use `generate_llm_messages`.\")\n",
            "INFO  [pilot.scene.base_chat] Requert: \n",
            "{'model': 'chatgpt_proxyllm', 'prompt': 'human:안녕###', 'messages': [ModelMessage(role='human', content='안녕')], 'temperature': 0.6, 'max_new_tokens': 1024, 'echo': False}\n",
            "INFO  [pilot.awel.runner.job_manager] Save call data to node a1b118b4-3891-405a-a695-e4760c7ebc23, call_data: {'data': {'model': 'chatgpt_proxyllm', 'prompt': 'human:안녕###', 'messages': [ModelMessage(role='human', content='안녕')], 'temperature': 0.6, 'max_new_tokens': 1024, 'echo': False, 'span_id': 'fbc8374a-04eb-42e6-b893-232142e78812:60b3fcf7-1f6f-4933-97a0-6a689a25072d', 'model_cache_enable': False}}\n",
            "INFO  [pilot.awel.runner.local_runner] Begin run workflow from end operator, id: e0cefa4e-8bf0-403e-9984-6a7a661b1b32, call_data: {'data': {'model': 'chatgpt_proxyllm', 'prompt': 'human:안녕###', 'messages': [ModelMessage(role='human', content='안녕')], 'temperature': 0.6, 'max_new_tokens': 1024, 'echo': False, 'span_id': 'fbc8374a-04eb-42e6-b893-232142e78812:60b3fcf7-1f6f-4933-97a0-6a689a25072d', 'model_cache_enable': False}}\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mPOST /api/v1/chat/completions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "INFO  [pilot.awel.operator.common_operator] branch_input_ctxs 0 result None, is_empty: True\n",
            "INFO  [pilot.awel.operator.common_operator] Skip node name llm_model_cache_node\n",
            "INFO  [pilot.awel.operator.common_operator] branch_input_ctxs 1 result True, is_empty: False\n",
            "INFO  [pilot.awel.runner.local_runner] Skip node name llm_model_cache_node, node id 4aac9919-7c3b-4b13-a1be-eb53d4bd1e37\n",
            "INFO  [pilot.model.model_adapter] No conv from model_path chatgpt_proxyllm or no messages in params, OldLLMModelAdaperWrapper(pilot.model.adapter.ProxyllmAdapter)\n",
            "model prompt: \n",
            "\n",
            "human:안녕###\n",
            "\n",
            "stream output:\n",
            "\n",
            "INFO  [pilot.model.proxy.llms.chatgpt] Model: <pilot.model.proxy.llms.proxy_model.ProxyModel object at 0x79b130e7d120>, model_params: \n",
            "\n",
            "=========================== ProxyModelParameters ===========================\n",
            "\n",
            "model_name: chatgpt_proxyllm\n",
            "model_path: chatgpt_proxyllm\n",
            "proxy_server_url: https://api.openai.com/v1/chat/completions\n",
            "proxy_api_key: {******}\n",
            "proxy_api_base: None\n",
            "proxy_api_app_id: None\n",
            "proxy_api_type: None\n",
            "proxy_api_version: None\n",
            "http_proxy: None\n",
            "proxyllm_backend: None\n",
            "model_type: proxy\n",
            "device: cuda\n",
            "prompt_template: None\n",
            "max_context_size: 4096\n",
            "\n",
            "======================================================================\n",
            "\n",
            "\n",
            "INFO  [pilot.model.proxy.llms.chatgpt] Send request to real model gpt-3.5-turbo\n",
            "ERROR [pilot.model.cluster.worker.default_worker] Model inference error, detail: Traceback (most recent call last):\n",
            "  File \"/content/DB-GPT/pilot/model/cluster/worker/default_worker.py\", line 154, in generate_stream\n",
            "    for output in generate_stream_func(\n",
            "  File \"/content/DB-GPT/pilot/model/llm_out/proxy_llm.py\", line 38, in proxyllm_generate_stream\n",
            "    yield from generator_function(model, tokenizer, params, device, context_len)\n",
            "  File \"/content/DB-GPT/pilot/model/proxy/llms/chatgpt.py\", line 172, in chatgpt_generate_stream\n",
            "    res = client.chat.completions.create(messages=history, **payloads)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 299, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 598, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1063, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 842, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 885, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: {sk-8VcY*****************************************cL9}. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
            "\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mGET /api/v1/chat/dialogue/list HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "/prompt/list params:  chat_scene=None sub_chat_scene=None prompt_type='common' content=None user_name=None prompt_name=None\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mPOST /prompt/list HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     49.169.63.226:0 - \"\u001b[1mPOST /api/v1/chat/dialogue/scenes HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3pe4RMChAl1",
        "outputId": "5de89005-0de8-4323-cef3-80fb97b232b1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-23 19:07:55--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 18.205.222.128, 52.202.168.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13921656 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.2’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.28M  39.6MB/s    in 0.3s    \n",
            "\n",
            "2023-11-23 19:07:56 (39.6 MB/s) - ‘ngrok-stable-linux-amd64.zip.2’ saved [13921656/13921656]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./ngrok authtoken 2YabjHcQen70qU5x5MLD7pVjdVo_JdLrfwSJXYUztQUzZdyh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE1diLJpnELP",
        "outputId": "07b03576-4d18-4c83-a409-7687a3876656"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 5000 &')"
      ],
      "metadata": {
        "id": "R8OpLBDGk7lH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-GU9LBSljID",
        "outputId": "ab718331-32d1-4790-ccc5-09590d0a6655"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://a83e-35-238-164-104.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZ8biEUFnVwW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
