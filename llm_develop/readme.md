llm_test의 chat_c 파일은 내 허깅페이스에서 file목록에 chat_c.egg라는 압축파일로 저장했음 

허깅페이스의 7B 한국어 모델들을 불러오고 test -> synatra 7B 모델이 가장 좋았음
내가 PEFT의 qLORA 방식으로 저장된 finetuning 모델을 가져오고 test
temperature 파라미타와 length_penalty 파라미타를 추가하니 반복되는 문제가 사라짐   

참고 : https://docs.google.com/document/d/1v16ZHSVpXmFfZ9GkIGRAD3nFaggtwEnsQwLPsCTlKqA/edit


